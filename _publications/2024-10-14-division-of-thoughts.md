---
title: "Division-of-Thoughts: Harnessing Hybrid Language Model Synergy for Efficient On-Device LLM Agents"
collection: publications
category: preprints
permalink: /publication/2024-division-of-thoughts
excerpt: 'We propose a novel collaborative reasoning framework that optimizes the synergy between edge-deployed small language models and cloud-based large language models, significantly reducing costs while maintaining performance.'
date: 2024-10-14
venue: 'Preprint'
paperurl: 'TBD'
citation: 'Citation details pending.'
---

This research addresses the growing need for efficient edge AI applications by introducing a novel framework for coordinating on-device and cloud-based language models.

Key Innovations:
* **Task Decomposer**: Leverages language models' inherent planning abilities to break down complex queries into manageable sub-tasks
* **Task Scheduler**: Creates dependency graphs for sub-tasks, enabling parallel processing and identifying critical paths
* **Plug-and-Play Adapter**: A non-intrusive task head for small language models (SLMs) that optimizes task allocation
* **Self-Reinforced Tree Search**: Novel algorithm for generating high-quality sub-task allocation datasets

Performance Improvements:
* 66.12% reduction in average reasoning time
* 83.57% reduction in API costs
* Maintained reasoning accuracy comparable to baseline methods

Impact:
This work represents a significant advancement in edge-cloud AI collaboration, making sophisticated language model applications more accessible and efficient for edge devices.

Broader Applications:
* On-device web search assistants
* Edge computing scenarios
* Resource-constrained AI applications

This research contributes to making advanced AI capabilities more accessible while maintaining high performance standards and reducing operational costs.
